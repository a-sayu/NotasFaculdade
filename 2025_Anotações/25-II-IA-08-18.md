# 08.18 - Aula

## Slide: [[25-II-IA-Aula06.pdf|Aprendizado Ativo 1]]

> Possui Excalidraw: [[25-II-IA-08-18.excalidraw|Excalidraw]]

Processo de de Decisão de Markov, foi passado na aula anterior, nele vimos a diferença de estados e q-estados, em que ele veio apartir de uma ação. Não é só o s, é o s,a (estado a partir de uma ação)

Para cada estado e uma ação, é feito um peso de utilidade dessa estado em conjunto com a ação. Após uma grande quantidade de episódois, o Q-Learning converge para q-valores ótimos.

> *pesq* : Deterministica x Não Deterministica

> *c* : atualmente está em aproximação linear - exemplo (caracteristicas)

Ele está fazendo os calculos com exemplo de desenho

![[25-II-IA-08-18.excalidraw#^frame=c7NZ1UW3UGW2UGqqni4mX]]

---

A parte de aprendizado é interessante depois do exemplo.

> *c* : eu não estou acompanhando, o que significa o dobro de esforço para entender depois.

---
$x^2$

Se meu x vale 10 quanto vale meu $x^2$? 100

x = 9? 81

$f(x,y) = x + y^2$ quero minimizar esse valor

Tenho dois casos: (10, 10) e (9, 10), qual será meu x'?

x' = 10 (x antigo) - alfa 1 \* \[ 10-9 \] = 10 - 0,5 \* 1 = 10,5
y' = 10 (y antigo) - alfa \* 1 \* \[10 - 10\] = 10 - 0,5 \* 0; = 10

Qual que eu devo modificar/deu maior impacto? o x'! Pois foi o que deu variação.